#!/usr/bin/env ruby
# frozen_string_literal: true

require 'optparse'

$LOAD_PATH.unshift(File.expand_path('../lib', __dir__))

require 'appydave/tools'

# DAM (Video Asset Tools) - CLI for video project management
class VatCLI
  def initialize
    @commands = {
      'help' => method(:help_command),
      'list' => method(:list_command),
      'status' => method(:status_command),
      's3-up' => method(:s3_up_command),
      's3-down' => method(:s3_down_command),
      's3-status' => method(:s3_status_command),
      's3-cleanup-remote' => method(:s3_cleanup_remote_command),
      's3-cleanup-local' => method(:s3_cleanup_local_command),
      'archive' => method(:archive_command),
      'manifest' => method(:manifest_command),
      'sync-ssd' => method(:sync_ssd_command),
      'repo-status' => method(:repo_status_command),
      'repo-sync' => method(:repo_sync_command),
      'repo-push' => method(:repo_push_command),
      's3-share' => method(:s3_share_command),
      's3-discover' => method(:s3_discover_command),
      's3-scan' => method(:s3_scan_command),
      # Deprecated aliases (for backward compatibility)
      's3-cleanup' => method(:s3_cleanup_remote_command),
      'cleanup-local' => method(:s3_cleanup_local_command)
    }
  end

  def run
    command, *args = ARGV

    if command.nil?
      puts 'DAM - Video Asset Tools'
      puts 'Usage: dam [command] [options]'
      puts "Run 'dam help' for more information."
      exit
    end

    if @commands.key?(command)
      @commands[command].call(args)
    else
      puts "Unknown command: #{command}"
      puts "Run 'dam help' for available commands."
      exit 1
    end
  end

  private

  # Show help information
  # rubocop:disable Metrics/CyclomaticComplexity
  def help_command(args)
    topic = args[0]

    case topic
    when 'brands'
      show_brands_help
    when 'workflows'
      show_workflows_help
    when 'config'
      show_config_help
    when 'list'
      show_list_help
    when 's3-share'
      show_s3_share_help
    when 's3-discover'
      show_s3_discover_help
    when 's3-up', 's3-down', 's3-status', 's3-cleanup-remote', 's3-cleanup-local', 'archive', 'manifest', 'sync-ssd'
      show_s3_help(topic)
    when 's3-cleanup', 'cleanup-local'
      # Deprecated command names - show deprecation notice and new help
      puts "‚ö†Ô∏è  '#{topic}' is deprecated. Use the new command name instead:\n\n"
      new_name = topic == 's3-cleanup' ? 's3-cleanup-remote' : 's3-cleanup-local'
      show_s3_help(new_name)
    else
      show_main_help
    end
  end
  # rubocop:enable Metrics/CyclomaticComplexity

  # List brands and projects
  def list_command(args)
    args = args.reject { |arg| arg.start_with?('--') || arg.start_with?('-') }

    brand_arg = args[0]
    pattern_arg = args[1]

    if brand_arg.nil?
      # List all brands with summary
      Appydave::Tools::Dam::ProjectListing.list_brands_with_counts
    elsif pattern_arg
      # Pattern matching
      Appydave::Tools::Dam::ProjectListing.list_with_pattern(brand_arg, pattern_arg)
    else
      # Specific brand
      Appydave::Tools::Dam::ProjectListing.list_brand_projects(brand_arg)
    end
  rescue StandardError => e
    puts "‚ùå Error: #{e.message}"
    exit 1
  end

  # S3 Upload
  def s3_up_command(args)
    options = parse_s3_args(args, 's3-up')
    s3_ops = Appydave::Tools::Dam::S3Operations.new(options[:brand], options[:project])
    s3_ops.upload(dry_run: options[:dry_run])
  rescue StandardError => e
    puts "‚ùå Error: #{e.message}"
    exit 1
  end

  # S3 Download
  def s3_down_command(args)
    options = parse_s3_args(args, 's3-down')
    s3_ops = Appydave::Tools::Dam::S3Operations.new(options[:brand], options[:project])
    s3_ops.download(dry_run: options[:dry_run])
  rescue StandardError => e
    puts "‚ùå Error: #{e.message}"
    exit 1
  end

  # S3 Status
  def s3_status_command(args)
    options = parse_s3_args(args, 's3-status')
    s3_ops = Appydave::Tools::Dam::S3Operations.new(options[:brand], options[:project])
    s3_ops.status
  rescue StandardError => e
    puts "‚ùå Error: #{e.message}"
    exit 1
  end

  # S3 Cleanup Remote
  def s3_cleanup_remote_command(args)
    options = parse_s3_args(args, 's3-cleanup-remote')
    s3_ops = Appydave::Tools::Dam::S3Operations.new(options[:brand], options[:project])
    s3_ops.cleanup(force: options[:force], dry_run: options[:dry_run])
  rescue StandardError => e
    puts "‚ùå Error: #{e.message}"
    exit 1
  end

  # S3 Cleanup Local
  def s3_cleanup_local_command(args)
    options = parse_s3_args(args, 's3-cleanup-local')
    s3_ops = Appydave::Tools::Dam::S3Operations.new(options[:brand], options[:project])
    s3_ops.cleanup_local(force: options[:force], dry_run: options[:dry_run])
  rescue StandardError => e
    puts "‚ùå Error: #{e.message}"
    exit 1
  end

  # Share file via pre-signed URL
  def s3_share_command(args)
    options = parse_share_args(args)

    share_ops = Appydave::Tools::Dam::ShareOperations.new(options[:brand], options[:project])
    share_ops.generate_links(files: options[:file], expires: options[:expires], download: options[:download])
  rescue StandardError => e
    puts "‚ùå Error: #{e.message}"
    exit 1
  end

  # Discover files in S3 for a project
  def s3_discover_command(args)
    options = parse_discover_args(args)
    files = fetch_s3_files(options[:brand_key], options[:project_id])

    return if handle_empty_files?(files, options[:brand_key], options[:project_id])

    display_s3_files(files, options[:brand_key], options[:project_id], options[:shareable])
  rescue StandardError => e
    puts "‚ùå Error: #{e.message}"
    exit 1
  end

  # Archive project to SSD
  def archive_command(args)
    options = parse_s3_args(args, 'archive')
    s3_ops = Appydave::Tools::Dam::S3Operations.new(options[:brand], options[:project])
    s3_ops.archive(force: options[:force], dry_run: options[:dry_run])
  rescue StandardError => e
    puts "‚ùå Error: #{e.message}"
    exit 1
  end

  # Generate manifest
  def manifest_command(args)
    all_brands = args.include?('--all')
    args = args.reject { |arg| arg.start_with?('--') }
    brand_arg = args[0]

    if all_brands
      generate_all_manifests
    elsif brand_arg
      generate_single_manifest(brand_arg)
    else
      show_manifest_usage
    end
  rescue StandardError => e
    puts "‚ùå Error: #{e.message}"
    exit 1
  end

  def generate_all_manifests
    Appydave::Tools::Configuration::Config.configure
    brands_config = Appydave::Tools::Configuration::Config.brands

    results = []
    brands_config.brands.each do |brand_info|
      brand_key = brand_info.key
      puts ''
      puts '=' * 60

      generator = Appydave::Tools::Dam::ManifestGenerator.new(brand_key)
      result = generator.generate
      results << result if result
    end

    display_manifest_summary(results)
  end

  def generate_single_manifest(brand_arg)
    Appydave::Tools::Dam::Config.expand_brand(brand_arg)
    ENV['BRAND_PATH'] = Appydave::Tools::Dam::Config.brand_path(brand_arg)

    generator = Appydave::Tools::Dam::ManifestGenerator.new(brand_arg)
    generator.generate
  end

  def show_manifest_usage
    puts 'Usage: dam manifest <brand> [--all]'
    puts ''
    puts 'Examples:'
    puts '  dam manifest appydave        # Generate manifest for AppyDave brand'
    puts '  dam manifest --all           # Generate manifests for all brands'
    exit 1
  end

  def display_manifest_summary(results)
    puts ''
    puts '=' * 60
    puts 'üìã Summary - Generated Manifests:'
    puts ''

    successful = results.select { |r| r[:success] }
    failed = results.reject { |r| r[:success] }

    successful.each do |result|
      brand_display = result[:brand].ljust(15)
      puts "‚úÖ #{brand_display} #{result[:path]}"
    end

    failed.each do |result|
      brand_display = result[:brand].ljust(15)
      puts "‚ùå #{brand_display} No projects found"
    end

    puts ''
    puts "Total manifests generated: #{successful.size}"
  end

  # Sync light files from SSD to local
  def sync_ssd_command(args)
    dry_run = args.include?('--dry-run')
    args = args.reject { |arg| arg.start_with?('--') }
    brand_arg = args[0]

    if brand_arg
      # Sync specific brand
      Appydave::Tools::Dam::Config.expand_brand(brand_arg)
      ENV['BRAND_PATH'] = Appydave::Tools::Dam::Config.brand_path(brand_arg)

      syncer = Appydave::Tools::Dam::SyncFromSsd.new(brand_arg)
      syncer.sync(dry_run: dry_run)
    else
      puts 'Usage: dam sync-ssd <brand> [--dry-run]'
      puts ''
      puts 'Sync light files (subtitles, images, docs) from SSD to local for archived projects.'
      puts 'Does NOT sync heavy video files (MP4, MOV, etc.).'
      puts ''
      puts 'Examples:'
      puts '  dam sync-ssd appydave        # Sync all AppyDave projects from SSD'
      puts '  dam sync-ssd appydave --dry-run  # Preview what would be synced'
      exit 1
    end
  rescue StandardError => e
    puts "‚ùå Error: #{e.message}"
    exit 1
  end

  # Show unified status (local/S3/SSD/git)
  def status_command(args)
    args = args.reject { |arg| arg.start_with?('--') }
    brand_arg = args[0]
    project_arg = args[1]

    if brand_arg.nil?
      puts '‚ùå Brand argument required'
      puts 'Usage: dam status <brand> [project]'
      exit 1
    end

    brand_key = brand_arg
    project_id = project_arg ? Appydave::Tools::Dam::ProjectResolver.resolve(brand_arg, project_arg) : nil

    status = Appydave::Tools::Dam::Status.new(brand_key, project_id)
    status.show
  rescue StandardError => e
    puts "‚ùå Error: #{e.message}"
    exit 1
  end

  # Show git status for brand repositories
  def repo_status_command(args)
    all = args.include?('--all')
    args = args.reject { |arg| arg.start_with?('--') }
    brand_arg = args[0]

    if all
      # Show status for all brands
      Appydave::Tools::Dam::RepoStatus.new.show_all
    elsif brand_arg
      # Show status for specific brand
      Appydave::Tools::Dam::RepoStatus.new(brand_arg).show
    else
      puts 'Usage: dam repo-status <brand> [--all]'
      puts ''
      puts 'Check git status for brand repositories.'
      puts ''
      puts 'Examples:'
      puts '  dam repo-status appydave    # Show git status for AppyDave brand'
      puts '  dam repo-status --all       # Show git status for all brands'
      exit 1
    end
  rescue StandardError => e
    puts "‚ùå Error: #{e.message}"
    exit 1
  end

  # Sync (pull) brand repositories
  def repo_sync_command(args)
    all = args.include?('--all')
    args = args.reject { |arg| arg.start_with?('--') }
    brand_arg = args[0]

    if all
      # Sync all brands
      Appydave::Tools::Dam::RepoSync.new.sync_all
    elsif brand_arg
      # Sync specific brand
      Appydave::Tools::Dam::RepoSync.new(brand_arg).sync
    else
      puts 'Usage: dam repo-sync <brand> [--all]'
      puts ''
      puts 'Pull updates for brand repositories.'
      puts ''
      puts 'Examples:'
      puts '  dam repo-sync appydave    # Pull updates for AppyDave brand'
      puts '  dam repo-sync --all       # Pull updates for all brands'
      exit 1
    end
  rescue StandardError => e
    puts "‚ùå Error: #{e.message}"
    exit 1
  end

  # Push brand repository changes
  def repo_push_command(args)
    args = args.reject { |arg| arg.start_with?('--') }
    brand_arg = args[0]
    project_arg = args[1]

    if brand_arg.nil?
      puts 'Usage: dam repo-push <brand> [project]'
      puts ''
      puts 'Push changes for brand repository.'
      puts ''
      puts 'Examples:'
      puts '  dam repo-push appydave       # Push all changes for AppyDave brand'
      puts '  dam repo-push appydave b65   # Validate project exists before push'
      exit 1
    end

    project_id = project_arg ? Appydave::Tools::Dam::ProjectResolver.resolve(brand_arg, project_arg) : nil

    Appydave::Tools::Dam::RepoPush.new(brand_arg, project_id).push
  rescue StandardError => e
    puts "‚ùå Error: #{e.message}"
    exit 1
  end

  # Parse S3 command arguments
  def parse_s3_args(args, command)
    dry_run = args.include?('--dry-run')
    force = args.include?('--force')
    args = args.reject { |arg| arg.start_with?('--') }

    brand_arg = args[0]
    project_arg = args[1]

    if brand_arg.nil?
      # Auto-detect from PWD
      brand, project_id = Appydave::Tools::Dam::ProjectResolver.detect_from_pwd
      if brand.nil? || project_id.nil?
        puts '‚ùå Could not auto-detect brand/project from current directory'
        puts "Usage: dam #{command} <brand> <project> [--dry-run]"
        exit 1
      end
      brand_key = brand # Already detected, use as-is
    else
      brand_key = brand_arg # Use the shortcut/key (e.g., 'appydave')
      brand = Appydave::Tools::Dam::Config.expand_brand(brand_arg) # Expand for path resolution
      project_id = Appydave::Tools::Dam::ProjectResolver.resolve(brand_arg, project_arg)
    end

    # Set ENV for compatibility with ConfigLoader
    ENV['BRAND_PATH'] = Appydave::Tools::Dam::Config.brand_path(brand)

    { brand: brand_key, project: project_id, dry_run: dry_run, force: force }
  end

  def parse_share_args(args)
    # Extract --expires flag
    expires = '7d' # default
    if (expires_index = args.index('--expires'))
      expires = args[expires_index + 1]
      args.delete_at(expires_index + 1)
      args.delete_at(expires_index)
    end

    # Extract --download flag
    download = args.include?('--download')

    # Remove other flags
    args = args.reject { |arg| arg.start_with?('--') }

    brand_arg = args[0]
    project_arg = args[1]
    file_arg = args[2]

    show_share_usage_and_exit if brand_arg.nil? || project_arg.nil? || file_arg.nil?

    brand_key = brand_arg
    brand = Appydave::Tools::Dam::Config.expand_brand(brand_arg)
    project_id = Appydave::Tools::Dam::ProjectResolver.resolve(brand_arg, project_arg)

    # Set ENV for compatibility with ConfigLoader
    ENV['BRAND_PATH'] = Appydave::Tools::Dam::Config.brand_path(brand)

    { brand: brand_key, project: project_id, file: file_arg, expires: expires, download: download }
  end

  def show_share_usage_and_exit
    puts 'Usage: dam s3-share <brand> <project> <file> [--expires 7d] [--download]'
    puts ''
    puts 'Options:'
    puts '  --expires TIME    Expiry time (default: 7d)'
    puts '  --download        Force download instead of viewing in browser'
    puts ''
    puts 'Examples:'
    puts '  dam s3-share appydave b70 video.mp4'
    puts '  dam s3-share appydave b70 video.mp4 --expires 24h'
    puts '  dam s3-share appydave b70 video.mp4 --download'
    puts '  dam s3-share voz boy-baker final-edit.mov --expires 3d --download'
    exit 1
  end

  def parse_discover_args(args)
    shareable = args.include?('--shareable')
    args = args.reject { |arg| arg.start_with?('--') }

    brand_arg = args[0]
    project_arg = args[1]

    if brand_arg.nil? || project_arg.nil?
      puts 'Usage: dam s3-discover <brand> <project> [--shareable]'
      puts ''
      puts 'Examples:'
      puts '  dam s3-discover appydave b70              # List files'
      puts '  dam s3-discover appydave b70 --shareable  # Generate share commands'
      exit 1
    end

    brand_key = brand_arg
    brand = Appydave::Tools::Dam::Config.expand_brand(brand_arg)
    project_id = Appydave::Tools::Dam::ProjectResolver.resolve(brand_arg, project_arg)

    # Set ENV for compatibility with ConfigLoader
    ENV['BRAND_PATH'] = Appydave::Tools::Dam::Config.brand_path(brand)

    { brand_key: brand_key, project_id: project_id, shareable: shareable }
  end

  def fetch_s3_files(brand_key, project_id)
    s3_ops = Appydave::Tools::Dam::S3Operations.new(brand_key, project_id)
    s3_ops.list_s3_files
  end

  def handle_empty_files?(files, brand_key, project_id)
    return false unless files.empty?

    puts "üì≠ No files found in S3 for #{brand_key}/#{project_id}"
    puts ''
    puts 'Upload files first:'
    puts "  dam s3-up #{brand_key} #{project_id}"
    true
  end

  # rubocop:disable Metrics/MethodLength, Metrics/AbcSize
  def display_s3_files(files, brand_key, project_id, shareable)
    brand_display = Appydave::Tools::Dam::Config.expand_brand(brand_key)

    puts ''
    puts "üîç S3 Discovery: #{brand_display}/#{project_id}"
    puts ''

    if shareable
      # Legacy --shareable mode: just list share commands
      files.each do |file_info|
        s3_key = file_info['Key']
        filename = File.basename(s3_key)
        puts "dam s3-share #{brand_key} #{project_id} #{filename}"
      end
      puts ''
      return
    end

    # Table format
    puts 'FILES                                    SIZE        LAST MODIFIED'
    puts '-' * 72

    total_bytes = 0
    files.each do |file_info|
      s3_key = file_info['Key']
      filename = File.basename(s3_key)
      size = file_info['Size']
      last_modified = file_info['LastModified']

      total_bytes += size

      # Format columns
      file_col = filename.ljust(40)
      size_col = format_bytes(size).rjust(10)
      date_col = last_modified ? last_modified.strftime('%Y-%m-%d %H:%M') : 'N/A'.ljust(16)

      puts "#{file_col} #{size_col}     #{date_col}"
    end

    puts '-' * 72
    puts "Total: #{files.size} #{files.size == 1 ? 'file' : 'files'}, #{format_bytes(total_bytes)}"

    # Quick actions section
    puts ''
    puts 'üìã Quick Actions:'

    # Share first file (most likely the video)
    if files.any?
      first_file = File.basename(files.first['Key'])
      puts "  dam s3-share #{brand_key} #{project_id} #{first_file}  # Share first file (7-day link)"
    end

    # Download all files
    puts "  dam s3-down #{brand_key} #{project_id}       # Download all files"

    # Cleanup preview
    puts "  dam s3-cleanup-remote #{brand_key} #{project_id} --dry-run  # Preview cleanup"

    puts ''
  end
  # rubocop:enable Metrics/MethodLength, Metrics/AbcSize

  # Help text methods
  # rubocop:disable Metrics/MethodLength
  def show_main_help
    puts <<~HELP
      DAM (Video Asset Tools) - Unified CLI for video project management

      Usage: dam [command] [options]

      Available Commands:
        help [command]              Show help information
        list [brand] [pattern]      List brands/projects

        Status & Monitoring:
        status <brand> [project]         Show unified status (local/S3/SSD/git)

        Git Repository Commands:
        repo-status <brand> [--all]      Check git status for brand repos
        repo-sync <brand> [--all]        Pull updates for brand repos
        repo-push <brand> [project]      Push changes for brand repo

        S3 Sync Commands:
        s3-up <brand> <project>          Upload to S3 staging
        s3-down <brand> <project>        Download from S3 staging
        s3-status <brand> [project]      Check sync status
        s3-cleanup-remote <brand> <project>  Delete S3 files
        s3-cleanup-local <brand> <project>   Delete local s3-staging files

        S3 Sharing Commands:
        s3-discover <brand> <project>    List files available in S3
        s3-share <brand> <project> <file> Generate shareable pre-signed URL

        S3 Data Commands:
        s3-scan <brand> [--all]          Scan S3 bucket for actual file data

        Archive Commands:
        archive <brand> <project>        Copy project to SSD backup
        manifest <brand> [--all]         Generate project manifest
        sync-ssd <brand>                 Restore light files from SSD

      List Modes:
        dam list                   All brands with counts/sizes
        dam list appydave          All projects for brand
        dam list appydave 'b6*'    Pattern matching

      Help Topics:
        dam help brands            List available brands
        dam help workflows         Explain FliVideo vs Storyline workflows
        dam help config            Configuration file details

      Examples:
        dam list
        dam status appydave
        dam status appydave b65
        dam repo-status appydave
        dam repo-sync appydave
        dam s3-up appydave b65
        dam s3-down voz boy-baker --dry-run
        dam s3-status appydave b65
        dam s3-discover appydave b70
        dam s3-discover appydave b70 --shareable
        dam s3-share appydave b70 video.mp4
        dam s3-share appydave b70 video.mp4 --expires 24h
        dam s3-scan appydave
        dam s3-scan --all
        dam s3-cleanup-remote appydave b65 --force

      For more information: https://github.com/appydave/appydave-tools
    HELP
  end

  def show_brands_help
    puts <<~HELP
      Available Brands

      DAM supports multi-tenant video project management with brand shortcuts:

      Brand Shortcuts:
        appydave  ‚Üí v-appydave         (AppyDave brand videos)
        voz       ‚Üí v-voz              (VOZ client videos)
        aitldr    ‚Üí v-aitldr           (AITLDR brand videos)
        kiros     ‚Üí v-kiros            (Kiros client videos)
        joy       ‚Üí v-beauty-and-joy   (Beauty & Joy brand)
        ss        ‚Üí v-supportsignal    (SupportSignal client)

      Usage:
        dam list                       # Show all brands with counts
        dam list appydave              # List all AppyDave projects
        dam list appydave 'b6*'        # List AppyDave projects matching pattern
        dam s3-up voz boy-baker        # Upload VOZ project
    HELP
  end

  def show_workflows_help
    puts <<~HELP
      Video Workflows

      DAM supports two primary video content workflows:

      1. FliVideo Workflow (AppyDave)
         - Sequential chapter-based recording
         - Projects follow pattern: [letter][number]-[name]
         - Example: b65-guy-monroe-marketing-plan
         - Short name support: b65 ‚Üí b65-guy-monroe-marketing-plan
         - Pattern matching: b6* ‚Üí all projects b60-b69

      2. Storyline Workflow (VOZ, AITLDR)
         - Script-first content creation
         - Projects use full descriptive names
         - Example: boy-baker, the-point
         - No short name expansion (exact match required)

      Project Organization:
        v-appydave/
          ‚îú‚îÄ‚îÄ b40-project-name/        # FliVideo pattern
          ‚îú‚îÄ‚îÄ b65-another-project/
          ‚îî‚îÄ‚îÄ archived/                # Completed projects

        v-voz/
          ‚îú‚îÄ‚îÄ boy-baker/               # Storyline pattern
          ‚îî‚îÄ‚îÄ the-point/

      Storage Strategy:
        Local ‚Üí S3 (90-day collaboration) ‚Üí SSD (long-term archive)
    HELP
  end

  def show_config_help
    puts <<~HELP
      Configuration

      DAM uses two configuration levels:

      1. System Configuration (settings.json)
         Location: ~/.config/appydave/settings.json
         Purpose: Define root directory for all video projects
         Format:
           {
             "video-projects-root": "/Users/yourname/dev/video-projects"
           }

         Setup:
           ad_config -c                # Create configuration
           ad_config -e                # Edit configuration

      2. Brand Configuration (.video-tools.env)
         Location: <brand-dir>/.video-tools.env
         Purpose: AWS credentials and S3 settings per brand
         Required Keys:
           AWS_ACCESS_KEY_ID=xxx
           AWS_SECRET_ACCESS_KEY=xxx
           AWS_REGION=us-east-1
           S3_BUCKET=your-bucket-name
           SSD_BASE=/path/to/external/drive

         Example:
           v-appydave/.video-tools.env
           v-voz/.video-tools.env

      Directory Structure:
        ~/.config/appydave/
        ‚îî‚îÄ‚îÄ settings.json              # System config

        /Users/yourname/dev/video-projects/
        ‚îú‚îÄ‚îÄ v-appydave/
        ‚îÇ   ‚îú‚îÄ‚îÄ .video-tools.env       # Brand-specific config
        ‚îÇ   ‚îî‚îÄ‚îÄ b65-project/
        ‚îî‚îÄ‚îÄ v-voz/
            ‚îú‚îÄ‚îÄ .video-tools.env
            ‚îî‚îÄ‚îÄ boy-baker/
    HELP
  end

  def show_list_help
    puts <<~HELP
      List Command

      Usage: dam list [brand] [pattern]

      Modes:
        1. List all brands with summary:
           dam list

        2. List projects for specific brand:
           dam list appydave

        3. Pattern matching:
           dam list appydave 'b6*'       # All projects b60-b69
           dam list appydave 'b4*'       # All projects b40-b49

      Examples:
        dam list                         # Tabular: brand, project count, size, modified
        dam list voz                     # Tabular: all VOZ projects with size/date
        dam list appydave 'b6*'          # Tabular: b60-b69 projects with size/date
    HELP
  end

  def show_s3_share_help
    puts <<~HELP
      S3 Share Command - Generate Shareable Pre-Signed URLs

      Generate time-limited secure URLs for sharing video files with clients.
      Recipients don't need AWS access - just click the link in their browser!

      Usage: dam s3-share <brand> <project> <file> [OPTIONS]

      Options:
        --expires TIME    Expiry time (default: 7d)
                         Examples: 24h, 48h, 3d, 7d
        --download        Force download instead of viewing in browser (default: inline viewing)

      How It Works:
        1. Generates pre-signed S3 URL (time-limited, secure)
        2. Copies URL to clipboard automatically
        3. Shows expiry date/time
        4. By default: Opens in browser (inline) - perfect for video playback
        5. With --download: Forces file download

      Examples:
        dam s3-share appydave b70 video.mp4
        # ‚Üí View in browser (default), 7-day expiry

        dam s3-share appydave b70 video.mp4 --download
        # ‚Üí Force download, 7-day expiry

        dam s3-share appydave b70 final-edit.mp4 --expires 24h
        # ‚Üí View in browser, 24-hour expiry for quick review

        dam s3-share voz boy-baker scene-01.mov --expires 3d --download
        # ‚Üí Force download, 3-day expiry for client approval

      Viewing Modes:
        üé¨ Default (inline):  Opens in browser - great for video playback
        üì• --download flag:   Forces download - better for archiving

      Security:
        ‚úÖ Time-limited (expires automatically)
        ‚úÖ Cryptographically signed (can't be tampered with)
        ‚úÖ No AWS state stored (signature encodes everything)
        ‚úÖ Revocable (delete S3 file if needed)
        ‚ö†Ô∏è  Anyone with URL can access (don't share publicly)

      Prerequisites:
        - File must be uploaded to S3 first
        - Run: dam s3-up <brand> <project>

      Use Cases:
        - Share videos with clients for review (inline)
        - Send final files for download (--download)
        - Provide temporary access to collaborators
        - Quick video sharing without email attachments

      For more information: https://github.com/appydave/appydave-tools
    HELP
  end

  def show_s3_discover_help
    puts <<~HELP
      S3 Discover Command - List Files in S3

      Discover what video files exist in S3 for a project.
      Useful before sharing to see available files.

      Usage: dam s3-discover <brand> <project> [--shareable]

      Modes:
        Default         List filenames only
        --shareable     Generate ready-to-run share commands

      Examples:
        dam s3-discover appydave b70
        # Output:
        # xmen.mp4
        # behind-the-scenes.mov

        dam s3-discover appydave b70 --shareable
        # Output:
        # dam s3-share appydave b70 xmen.mp4
        # dam s3-share appydave b70 behind-the-scenes.mov

      Workflow:
        1. Upload files: dam s3-up appydave b70
        2. Discover files: dam s3-discover appydave b70
        3. Share specific file: dam s3-share appydave b70 xmen.mp4

      Use Cases:
        - Find files available for sharing
        - Generate multiple share commands at once
        - Quick project file listing without downloading
        - Copy-paste shareable commands for clients

      Prerequisites:
        - Files must be uploaded to S3 first
        - Run: dam s3-up <brand> <project>

      For more information: https://github.com/appydave/appydave-tools
    HELP
  end

  # rubocop:disable Metrics/CyclomaticComplexity
  def show_s3_help(command)
    case command
    when 's3-up'
      puts <<~HELP
        S3 Upload Command

        Upload files from local s3-staging/ directory to S3 for collaboration.

        Usage: dam s3-up <brand> <project> [--dry-run]

        Features:
          - Smart sync: Skips unchanged files (MD5 comparison)
          - Progress tracking: Shows uploaded/skipped/failed counts
          - Dry-run support: Preview changes without uploading

        Examples:
          dam s3-up appydave b65              # Upload b65 project
          dam s3-up voz boy-baker --dry-run   # Preview upload
          dam s3-up                           # Auto-detect from PWD

        Notes:
          - Files must be in project's s3-staging/ directory
          - Requires AWS credentials in .video-tools.env
          - S3 path: staging/<brand>/<project>/
      HELP
    when 's3-down'
      puts <<~HELP
        S3 Download Command

        Download files from S3 to local s3-staging/ directory.

        Usage: dam s3-down <brand> <project> [--dry-run]

        Features:
          - Smart sync: Skips unchanged files (MD5 comparison)
          - Progress tracking: Shows downloaded/skipped/failed counts
          - Dry-run support: Preview changes without downloading

        Examples:
          dam s3-down appydave b65            # Download b65 project
          dam s3-down voz boy-baker --dry-run # Preview download
          dam s3-down                         # Auto-detect from PWD

        Notes:
          - Creates s3-staging/ directory if needed
          - Requires AWS credentials in .video-tools.env
      HELP
    when 's3-status'
      puts <<~HELP
        S3 Status Command

        Check sync status between local and S3 files.

        Usage: dam s3-status <brand> [project]

        Features:
          - Shows all files (S3 and local)
          - Indicates sync status: [synced], [modified], [S3 only], [local only]
          - Displays file sizes and totals
          - Shows file counts for both S3 and local

        Examples:
          dam s3-status appydave b65          # Check b65 status
          dam s3-status                       # Auto-detect from PWD

        Status Indicators:
          ‚úì  [synced]      - Local and S3 match (MD5)
          ‚ö†Ô∏è  [modified]   - Files differ between local and S3
          ‚òÅÔ∏è  [S3 only]    - File only in S3, not present locally
          üìÅ [local only]  - File only local, not uploaded to S3
      HELP
    when 's3-cleanup-remote'
      puts <<~HELP
        S3 Cleanup Remote Command

        Delete all S3 files for a project (use with caution).

        Usage: dam s3-cleanup-remote <brand> <project> --force [--dry-run]

        Features:
          - Requires --force flag for safety
          - Dry-run support: Preview deletions
          - Shows deleted/failed counts

        Examples:
          dam s3-cleanup-remote appydave b65 --dry-run  # Preview deletion
          dam s3-cleanup-remote appydave b65 --force    # Actually delete
          dam s3-cleanup-remote --force                 # Auto-detect from PWD

        ‚ö†Ô∏è  WARNING: This permanently deletes files from S3.
            Ensure you have local backups before running.

        Note: Old command 's3-cleanup' still works but is deprecated.
      HELP
    when 's3-cleanup-local'
      puts <<~HELP
        S3 Cleanup Local Command

        Delete all local files in the s3-staging/ directory for a project.

        Usage: dam s3-cleanup-local <brand> <project> --force [--dry-run]

        Features:
          - Requires --force flag for safety
          - Dry-run support: Preview deletions
          - Removes empty directories after cleanup
          - Shows deleted/failed counts

        Examples:
          dam s3-cleanup-local appydave b65 --dry-run  # Preview deletion
          dam s3-cleanup-local appydave b65 --force    # Actually delete
          dam s3-cleanup-local --force                 # Auto-detect from PWD

        Use Cases:
          - Free up disk space after uploading to S3
          - Clean up after completing collaboration
          - Remove local staging files when project is archived

        ‚ö†Ô∏è  NOTE: This only deletes LOCAL files in s3-staging/.
            Files in S3 are NOT affected. Use 's3-cleanup-remote' for that.

        Note: Old command 'cleanup-local' still works but is deprecated.
      HELP
    when 'archive'
      puts <<~HELP
        Archive Command

        Copy completed video project to SSD for long-term backup.

        Usage: dam archive <brand> <project> [--force] [--dry-run]

        Features:
          - Copies entire project directory to SSD backup location
          - Verifies SSD is mounted before archiving
          - Shows project size before copying
          - Optional: Delete local copy after successful archive (--force)
          - Dry-run support: Preview archive operation

        Examples:
          dam archive appydave b63 --dry-run   # Preview archive
          dam archive appydave b63             # Copy to SSD only
          dam archive appydave b63 --force     # Copy and delete local
          dam archive                          # Auto-detect from PWD

        Storage Strategy:
          Local ‚Üí S3 (90-day collaboration) ‚Üí SSD (long-term archive)

        Use Cases:
          - Archive completed and published projects
          - Free up local disk space for new projects
          - Long-term backup before removing from S3

        ‚ö†Ô∏è  NOTE: Without --force, the local project is NOT deleted.
            Use --force only after verifying SSD copy is successful.

        Configuration:
          - SSD backup path configured per brand in brands.json
          - Example: "ssd_backup": "/Volumes/T7/youtube-PUBLISHED/appydave"
      HELP
    when 'manifest'
      puts <<~HELP
        Manifest Command

        Generate a JSON manifest of all video projects for a brand.

        Usage: dam manifest <brand> [--all]

        Features:
          - Scans local and SSD storage locations
          - Tracks project distribution (local, SSD, both)
          - Identifies heavy files (video) vs light files (subtitles, images)
          - Calculates disk usage statistics
          - Validates project ID formats
          - Outputs projects.json in brand directory

        Examples:
          dam manifest appydave            # Generate manifest for AppyDave
          dam manifest voz                 # Generate manifest for VOZ
          dam manifest --all               # Generate manifests for all brands

        Output Location:
          - Single brand: <brand-path>/projects.json
          - All brands: Each brand gets its own manifest file

        Manifest Structure:
          {
            "config": {
              "brand": "appydave",
              "local_base": "/path/to/v-appydave",
              "ssd_base": "/Volumes/T7/youtube-PUBLISHED/appydave",
              "last_updated": "2025-11-09T23:00:00Z",
              "disk_usage": { ... }
            },
            "projects": [
              {
                "id": "b65-guy-monroe-marketing-plan",
                "storage": {
                  "ssd": { "exists": true, "path": "b65-guy-monroe-marketing-plan" },
                  "local": { "exists": true, "has_heavy_files": true, "has_light_files": true }
                }
              }
            ]
          }

        Use Cases:
          - Track which projects are archived to SSD
          - Identify projects with only light files (archived locally)
          - Generate disk usage reports
          - Validate project naming conventions
          - Prepare for sync-ssd operations
      HELP
    when 'sync-ssd'
      puts <<~HELP
        Sync from SSD Command

        Restore light files (subtitles, images, docs) from SSD to local for archived projects.
        Does NOT sync heavy video files (MP4, MOV, etc.).

        Usage: dam sync-ssd <brand> [--dry-run]

        Features:
          - Syncs ALL projects for a brand from manifest (projects.json)
          - Only copies light files: .srt, .vtt, .jpg, .png, .md, .txt, .json
          - Excludes heavy files: .mp4, .mov, .avi, .mkv, .webm
          - Smart skip: Skips files already synced (size comparison)
          - Creates archived/{range}/{project}/ directory structure
          - Dry-run support: Preview what will be synced

        Examples:
          dam sync-ssd appydave              # Sync all AppyDave projects
          dam sync-ssd appydave --dry-run    # Preview sync
          dam sync-ssd voz                   # Sync all VOZ projects

        Requirements:
          - Must have projects.json manifest (run: dam manifest <brand>)
          - SSD must be mounted
          - Projects must exist on SSD

        Behavior:
          - Only syncs projects that exist on SSD but NOT in local flat structure
          - Creates archived/{range}/{project}/ structure for restored files
          - Skips projects already in local flat structure
          - Skips files with same size (already synced)

        Use Cases:
          - Restore supporting files for archived projects
          - Get subtitles and images without huge video files
          - Prepare project for re-editing (download videos separately)
          - Access project documentation and metadata

        Storage Strategy:
          SSD (archive) ‚Üí Local archived/{range}/{project}/ (light files only)

        ‚ö†Ô∏è  NOTE: This only syncs LIGHT files. Heavy video files remain on SSD.
            If you need video files, copy them manually from SSD.

        Configuration:
          - SSD backup path configured per brand in brands.json
          - Manifest file: <brand-path>/projects.json
      HELP
    end
  end
  # rubocop:enable Metrics/CyclomaticComplexity
  # rubocop:enable Metrics/MethodLength

  # S3 Scan - Query AWS S3 for actual file listings
  def s3_scan_command(args)
    all_brands = args.include?('--all')
    args = args.reject { |arg| arg.start_with?('--') }
    brand_arg = args[0]

    if all_brands
      scan_all_brands_s3
    elsif brand_arg
      scan_single_brand_s3(brand_arg)
    else
      puts 'Usage: dam s3-scan <brand> [--all]'
      puts ''
      puts 'Scan S3 bucket to update project manifests with actual S3 file data.'
      puts ''
      puts 'Examples:'
      puts '  dam s3-scan appydave      # Scan AppyDave S3 bucket'
      puts '  dam s3-scan --all         # Scan all brands'
      exit 1
    end
  rescue StandardError => e
    puts "‚ùå Error: #{e.message}"
    puts e.backtrace.first(5).join("\n") if ENV['DEBUG']
    exit 1
  end

  # rubocop:disable Metrics/MethodLength, Metrics/CyclomaticComplexity, Metrics/AbcSize
  def scan_single_brand_s3(brand_arg)
    puts "üîÑ Scanning S3 for #{brand_arg}..."
    puts ''

    brand_key = brand_arg
    scanner = Appydave::Tools::Dam::S3Scanner.new(brand_key)

    # Get brand info for S3 path
    Appydave::Tools::Configuration::Config.configure
    brand_info = Appydave::Tools::Configuration::Config.brands.get_brand(brand_key)
    bucket = brand_info.aws.s3_bucket
    prefix = brand_info.aws.s3_prefix
    region = brand_info.aws.region

    # Spinner characters for progress
    spinner_chars = ['‚†ã', '‚†ô', '‚†π', '‚†∏', '‚†º', '‚†¥', '‚†¶', '‚†ß', '‚†á', '‚†è']
    spinner_index = 0

    print "üîç Scanning s3://#{bucket}/#{prefix}\n"
    print '    Scanning projects... '

    # Scan all projects with progress callback
    results = scanner.scan_all_projects(show_progress: false) do |current, total|
      print "\r    Scanning projects... #{spinner_chars[spinner_index]} (#{current}/#{total})"
      spinner_index = (spinner_index + 1) % spinner_chars.length
    end

    print "\r    Scanning projects... ‚úì (#{results.size} found)\n"
    puts ''

    if results.empty?
      puts "‚ö†Ô∏è  No projects found in S3 for #{brand_key}"
      puts '   This may indicate:'
      puts '   - No files uploaded to S3 yet'
      puts '   - S3 bucket or prefix misconfigured'
      puts '   - AWS credentials issue'
      return
    end

    # Load existing manifest
    brand_path = Appydave::Tools::Dam::Config.brand_path(brand_key)
    manifest_path = File.join(brand_path, 'projects.json')

    unless File.exist?(manifest_path)
      puts "‚ùå Manifest not found: #{manifest_path}"
      puts "   Run: dam manifest #{brand_key}"
      puts "   Then retry: dam s3-scan #{brand_key}"
      exit 1
    end

    manifest = JSON.parse(File.read(manifest_path), symbolize_names: true)

    # Identify matched and orphaned S3 projects
    local_project_ids = manifest[:projects].map { |p| p[:id] }
    matched_projects = results.slice(*local_project_ids)
    orphaned_projects = results.reject { |project_id, _| local_project_ids.include?(project_id) }

    # Merge S3 scan data into manifest for matched projects
    updated_count = 0
    manifest[:projects].each do |project|
      project_id = project[:id]
      s3_data = results[project_id]
      next unless s3_data

      project[:storage][:s3] = s3_data
      updated_count += 1
    end

    # Update timestamp and note
    manifest[:config][:last_updated] = Time.now.utc.iso8601
    manifest[:config][:note] = 'Auto-generated manifest with S3 scan data. Regenerate with: dam s3-scan'

    # Write updated manifest
    File.write(manifest_path, JSON.pretty_generate(manifest))

    # Display table
    display_s3_scan_table(matched_projects, orphaned_projects, bucket, prefix, region)

    # Summary
    total_manifest_projects = manifest[:projects].size
    missing_count = total_manifest_projects - matched_projects.size

    puts ''
    puts '‚ÑπÔ∏è  Summary:'
    puts "   ‚Ä¢ Updated #{updated_count} projects in manifest"
    puts "   ‚Ä¢ #{missing_count} local project(s) not yet uploaded to S3" if missing_count.positive?
    puts "   ‚Ä¢ Manifest: #{manifest_path}"
    puts ''
  end
  # rubocop:enable Metrics/MethodLength, Metrics/CyclomaticComplexity, Metrics/AbcSize

  # Display S3 scan results in table format
  # rubocop:disable Metrics/MethodLength, Metrics/AbcSize, Metrics/CyclomaticComplexity, Style/FormatStringToken
  def display_s3_scan_table(matched_projects, orphaned_projects, bucket, prefix, region)
    puts '‚úÖ S3 Projects Report'
    puts ''
    puts 'PROJECT                    FILES    SIZE        STATUS    LAST MODIFIED'
    puts '-' * 80

    # Display matched projects first (sorted alphabetically)
    matched_projects.sort.each do |project_id, data|
      files = data[:file_count].to_s.rjust(5)
      size = format_bytes(data[:total_bytes]).rjust(10)
      status = '‚úì'
      modified = data[:last_modified] ? Time.parse(data[:last_modified]).strftime('%Y-%m-%d %H:%M') : 'N/A'

      puts format('%-26s %5s %10s       %s       %s', project_id, files, size, status, modified)
    end

    # Display orphaned projects (sorted alphabetically)
    return if orphaned_projects.empty?

    puts '-' * 80
    orphaned_projects.sort.each do |project_id, data|
      files = data[:file_count].to_s.rjust(5)
      size = format_bytes(data[:total_bytes]).rjust(10)
      status = '‚ùå'
      modified = data[:last_modified] ? Time.parse(data[:last_modified]).strftime('%Y-%m-%d %H:%M') : 'N/A'

      puts format('%-26s %5s %10s       %s       %s', project_id, files, size, status, modified)
    end

    puts ''
    folder_word = orphaned_projects.size > 1 ? 'folders' : 'folder'
    puts "‚ö†Ô∏è  #{orphaned_projects.size} orphaned #{folder_word} found (no local project)"

    orphaned_projects.sort.each do |project_id, _data|
      # Build AWS Console URL
      project_prefix = "#{prefix}#{project_id}/"
      console_url = "https://#{region}.console.aws.amazon.com/s3/buckets/#{bucket}?prefix=#{project_prefix}&region=#{region}"
      puts "   ‚Üí #{project_id}"
      puts "     #{console_url}"
    end
  end
  # rubocop:enable Metrics/MethodLength, Metrics/AbcSize, Metrics/CyclomaticComplexity, Style/FormatStringToken

  # rubocop:disable Metrics/MethodLength, Metrics/AbcSize
  def scan_all_brands_s3
    Appydave::Tools::Configuration::Config.configure
    brands_config = Appydave::Tools::Configuration::Config.brands

    results = []
    brands_config.brands.each do |brand_info|
      brand_key = brand_info.key
      puts ''
      puts '=' * 60

      begin
        scan_single_brand_s3(brand_key)
        results << { brand: brand_key, success: true }
      rescue StandardError => e
        puts "‚ùå Failed to scan #{brand_key}: #{e.message}"
        results << { brand: brand_key, success: false, error: e.message }
      end
    end

    puts ''
    puts '=' * 60
    puts 'üìã Summary - S3 Scans:'
    puts ''

    successful = results.select { |r| r[:success] }
    failed = results.reject { |r| r[:success] }

    successful.each do |result|
      brand_display = result[:brand].ljust(15)
      puts "‚úÖ #{brand_display} Scanned successfully"
    end

    failed.each do |result|
      brand_display = result[:brand].ljust(15)
      puts "‚ùå #{brand_display} #{result[:error]}"
    end

    puts ''
    puts "Total brands scanned: #{successful.size}/#{results.size}"
  end
  # rubocop:enable Metrics/MethodLength, Metrics/AbcSize

  # Format bytes in human-readable format
  # rubocop:disable Style/FormatStringToken
  def format_bytes(bytes)
    return '0 B' if bytes.zero?

    units = %w[B KB MB GB TB]
    exp = (Math.log(bytes) / Math.log(1024)).to_i
    exp = [exp, units.length - 1].min

    format('%.1f %s', bytes.to_f / (1024**exp), units[exp])
  end
  # rubocop:enable Style/FormatStringToken
end

# Run CLI
VatCLI.new.run if $PROGRAM_NAME == __FILE__
